{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import deeplake\n",
    "from transformers import AutoTokenizer\n",
    "from trl.trainer import ConstantLengthDataset\n",
    "from peft import LoraConfig\n",
    "from transformers import TrainingArguments\n",
    "from transformers import AutoModelForCausalLM\n",
    "import torch\n",
    "from torch import nn\n",
    "from trl import SFTTrainer\n",
    "from transformers import AutoModelForCausalLM\n",
    "import torch\n",
    "from peft import PeftModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "|"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opening dataset in read-only mode as you don't have write permissions.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\\"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This dataset can be visualized in Jupyter Notebook by ds.visualize() or at https://app.activeloop.ai/genai360/FingGPT-sentiment-train-set\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\\"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hub://genai360/FingGPT-sentiment-train-set loaded successfully.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opening dataset in read-only mode as you don't have write permissions.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This dataset can be visualized in Jupyter Notebook by ds.visualize() or at https://app.activeloop.ai/genai360/FingGPT-sentiment-valid-set\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "-"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hub://genai360/FingGPT-sentiment-valid-set loaded successfully.\n",
      "\n",
      "Dataset(path='hub://genai360/FingGPT-sentiment-train-set', read_only=True, tensors=['input', 'instruction', 'output'])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " "
     ]
    }
   ],
   "source": [
    "# Connect to the training and testing datasets\n",
    "ds = deeplake.load('hub://genai360/FingGPT-sentiment-train-set')\n",
    "ds_valid = deeplake.load('hub://genai360/FingGPT-sentiment-valid-set')\n",
    "\n",
    "print(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_sample_text(example):\n",
    "    \"\"\"Prepare the text from a sample of the dataset.\"\"\"\n",
    "    text = f\"{example['instruction'].text()}\\n\\nContent: {example['input'].text()}\\n\\nSentiment: {example['output'].text()}\"\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': tensor([ 640,   90,    4,  ...,   41, 1948,   31]), 'labels': tensor([ 640,   90,    4,  ...,   41, 1948,   31])}\n"
     ]
    }
   ],
   "source": [
    "# Load the tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"facebook/opt-1.3b\")\n",
    "\n",
    "# Create the ConstantLengthDataset\n",
    "train_dataset = ConstantLengthDataset(\n",
    "    tokenizer,\n",
    "    ds,\n",
    "    formatting_func=prepare_sample_text,\n",
    "    infinite=True,\n",
    "    seq_length=1024\n",
    ")\n",
    "\n",
    "eval_dataset = ConstantLengthDataset(\n",
    "    tokenizer,\n",
    "    ds_valid,\n",
    "    formatting_func=prepare_sample_text,\n",
    "    seq_length=1024\n",
    ")\n",
    "\n",
    "\n",
    "# Show one sample from train set\n",
    "print(next(iter(train_dataset)))\n",
    "\n",
    "# for i,n in enumerate(train_dataset):\n",
    "#     print(n)\n",
    "#     break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Initialize the Model and Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "lora_config = LoraConfig(\n",
    "    r=16,\n",
    "    lora_alpha=32,\n",
    "    lora_dropout=0.05,\n",
    "    bias=\"none\",\n",
    "    task_type=\"CAUSAL_LM\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define TrainingArguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./OPT-fine_tuned-FinGPT-CPU\",\n",
    "    dataloader_drop_last=True,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    num_train_epochs=10,\n",
    "    logging_steps=5,\n",
    "    per_device_train_batch_size=12,\n",
    "    per_device_eval_batch_size=12,\n",
    "    learning_rate=1e-4,\n",
    "    lr_scheduler_type=\"cosine\",\n",
    "    warmup_steps=100,\n",
    "    gradient_accumulation_steps=1,\n",
    "    gradient_checkpointing=False,\n",
    "    fp16=False,\n",
    "    bf16=True,\n",
    "    weight_decay=0.05,\n",
    "    ddp_find_unused_parameters=False,\n",
    "    run_name=\"OPT-fine_tuned-FinGPT-CPU\",\n",
    "    report_to=\"wandb\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    \"facebook/opt-1.3b\", torch_dtype=torch.bfloat16\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in model.parameters():\n",
    "  param.requires_grad = False  # freeze the model - train adapters later\n",
    "  if param.ndim == 1:\n",
    "    # cast the small parameters (e.g. layernorm) to fp32 for stability\n",
    "    param.data = param.data.to(torch.float32)\n",
    "\n",
    "model.gradient_checkpointing_enable()  # reduce number of stored activations\n",
    "model.enable_input_require_grads()\n",
    "\n",
    "class CastOutputToFloat(nn.Sequential):\n",
    "  def forward(self, x): return super().forward(x).to(torch.float32)\n",
    "model.lm_head = CastOutputToFloat(model.lm_head)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = SFTTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=eval_dataset,\n",
    "    peft_config=lora_config,\n",
    "    packing=True,\n",
    ")\n",
    "\n",
    "print(\"Training...\")\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the base model (OPT-1.3B)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "  \"facebook/opt-1.3b\", return_dict=True, torch_dtype=torch.bfloat16\n",
    ")\n",
    "\n",
    "# Load the Lora model\n",
    "model = PeftModel.from_pretrained(model, \"./OPT-fine_tuned-FinGPT-CPU/<desired_checkpoint>/\")\n",
    "model.eval()\n",
    "model = model.merge_and_unload()\n",
    "\n",
    "# Save for future use\n",
    "model.save_pretrained(\"./OPT-fine_tuned-FinGPT-CPU/merged\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tokenizer(\"\"\"What is the sentiment of this news? Please choose an answer from {strong negative/moderately negative/mildly negative/neutral/mildly positive/moderately positive/strong positive}, then provide some short reasons.\\n\\n\n",
    "Content: UPDATE 1-AstraZeneca sells rare cancer drug to Sanofi for up to S300 mln.\\n\\nSentiment: \"\"\", return_tensors=\"pt\").to(\"cuda:0\")\n",
    "\n",
    "generation_output = model.generate(**inputs,\n",
    "                                    return_dict_in_generate=True,\n",
    "                                    output_scores=True,\n",
    "                                    max_length=256,\n",
    "                                    num_beams=1,\n",
    "                                    do_sample=True,\n",
    "                                    repetition_penalty=1.5,\n",
    "                                    length_penalty=2.)\n",
    "\n",
    "print( tokenizer.decode(generation_output['sequences'][0]) )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
