{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import deeplake\n",
    "from transformers import AutoTokenizer\n",
    "from trl.trainer import ConstantLengthDataset\n",
    "from peft import LoraConfig\n",
    "from transformers import TrainingArguments\n",
    "import torch\n",
    "from transformers import BitsAndBytesConfig\n",
    "from transformers import AutoModelForCausalLM\n",
    "from accelerate import Accelerator\n",
    "from torch import nn\n",
    "from trl import SFTTrainer\n",
    "from transformers import AutoModelForCausalLM\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\\"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opening dataset in read-only mode as you don't have write permissions.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "|"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This dataset can be visualized in Jupyter Notebook by ds.visualize() or at https://app.activeloop.ai/genai360/OpenOrca-1M-train-set\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "-"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hub://genai360/OpenOrca-1M-train-set loaded successfully.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opening dataset in read-only mode as you don't have write permissions.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "|"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This dataset can be visualized in Jupyter Notebook by ds.visualize() or at https://app.activeloop.ai/genai360/OpenOrca-1M-valid-set\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hub://genai360/OpenOrca-1M-valid-set loaded successfully.\n",
      "\n",
      "Dataset(path='hub://genai360/OpenOrca-1M-train-set', read_only=True, tensors=['id', 'question', 'response', 'system_prompt'])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " "
     ]
    }
   ],
   "source": [
    "# Connect to the training and testing datasets\n",
    "ds = deeplake.load('hub://genai360/OpenOrca-1M-train-set')\n",
    "ds_valid = deeplake.load('hub://genai360/OpenOrca-1M-valid-set')\n",
    "\n",
    "print(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_sample_text(example):\n",
    "    \"\"\"Prepare the text from a sample of the dataset.\"\"\"\n",
    "    text = f\"Question: {example['question'][0]}\\n\\nAnswer: {example['response'][0]}\"\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"facebook/opt-1.3b\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': tensor([   35,   255, 35354,  ...,     6,   321,   742]), 'labels': tensor([   35,   255, 35354,  ...,     6,   321,   742])}\n"
     ]
    }
   ],
   "source": [
    "train_dataset = ConstantLengthDataset(\n",
    "    tokenizer,\n",
    "    ds,\n",
    "    formatting_func=prepare_sample_text,\n",
    "    infinite=True,\n",
    "    seq_length=2048\n",
    ")\n",
    "\n",
    "eval_dataset = ConstantLengthDataset(\n",
    "    tokenizer,\n",
    "    ds_valid,\n",
    "    formatting_func=prepare_sample_text,\n",
    "    seq_length=1024\n",
    ")\n",
    "\n",
    "iterator = iter(train_dataset)\n",
    "sample = next(iterator)\n",
    "print(sample)\n",
    "\n",
    "train_dataset.start_iteration = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize the Model and Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "lora_config = LoraConfig(\n",
    "    r=16,\n",
    "    lora_alpha=32,\n",
    "    lora_dropout=0.05,\n",
    "    bias=\"none\",\n",
    "    task_type=\"CAUSAL_LM\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./OPT-fine_tuned-OpenOrca\",\n",
    "    dataloader_drop_last=True,\n",
    "    evaluation_strategy=\"steps\",\n",
    "    save_strategy=\"steps\",\n",
    "    num_train_epochs=2,\n",
    "    eval_steps=2000,\n",
    "    save_steps=2000,\n",
    "    logging_steps=1,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    learning_rate=1e-4,\n",
    "    lr_scheduler_type=\"cosine\",\n",
    "    warmup_steps=100,\n",
    "    gradient_accumulation_steps=1,\n",
    "    bf16=True,\n",
    "    weight_decay=0.05,\n",
    "    ddp_find_unused_parameters=False,\n",
    "    run_name=\"OPT-fine_tuned-OpenOrca\",\n",
    "    report_to=\"wandb\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quantization_config = BitsAndBytesConfig(\n",
    "   load_in_4bit=True,\n",
    "   bnb_4bit_quant_type=\"nf4\",\n",
    "   bnb_4bit_use_double_quant=True,\n",
    "   bnb_4bit_compute_dtype=torch.bfloat16\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "  \"facebook/opt-1.3b\",\n",
    "\tquantization_config=quantization_config,\n",
    "\tdevice_map={\"\": Accelerator().process_index}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in model.parameters():\n",
    "  param.requires_grad = False\n",
    "  if param.ndim == 1:\n",
    "    param.data = param.data.to(torch.float32)\n",
    "\n",
    "model.gradient_checkpointing_enable()\n",
    "model.enable_input_require_grads()\n",
    "\n",
    "class CastOutputToFloat(nn.Sequential):\n",
    "  def forward(self, x): return super().forward(x).to(torch.float32)\n",
    "model.lm_head = CastOutputToFloat(model.lm_head)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = SFTTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=eval_dataset,\n",
    "    peft_config=lora_config,\n",
    "    packing=True,\n",
    ")\n",
    "\n",
    "print(\"Training...\")\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "  \"facebook/opt-1.3b\", return_dict=True, torch_dtype=torch.bfloat16\n",
    ")\n",
    "\n",
    "from peft import PeftModel\n",
    "\n",
    "# Load the Lora model\n",
    "model = PeftModel.from_pretrained(model, \"./OPT-fine_tuned-OpenOrca/<step>\")\n",
    "model.eval()\n",
    "\n",
    "model = model.merge_and_unload()\n",
    "\n",
    "model.save_pretrained(\"./OPT-fine_tuned-OpenOrca/merged\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Training a Reward Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "|"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opening dataset in read-only mode as you don't have write permissions.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "-"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This dataset can be visualized in Jupyter Notebook by ds.visualize() or at https://app.activeloop.ai/genai360/Anthropic-hh-rlhf-train-set\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "-"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hub://genai360/Anthropic-hh-rlhf-train-set loaded successfully.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opening dataset in read-only mode as you don't have write permissions.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "|"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This dataset can be visualized in Jupyter Notebook by ds.visualize() or at https://app.activeloop.ai/genai360/Anthropic-hh-rlhf-test-set\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "|"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hub://genai360/Anthropic-hh-rlhf-test-set loaded successfully.\n",
      "\n",
      "Dataset(path='hub://genai360/Anthropic-hh-rlhf-train-set', read_only=True, tensors=['chosen', 'rejected'])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " "
     ]
    }
   ],
   "source": [
    "import deeplake\n",
    "\n",
    "ds = deeplake.load('hub://genai360/Anthropic-hh-rlhf-train-set')\n",
    "ds_valid = deeplake.load('hub://genai360/Anthropic-hh-rlhf-test-set')\n",
    "\n",
    "print(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tokenizer_config.json: 100%|██████████| 52.0/52.0 [00:00<00:00, 148kB/s]\n",
      "config.json: 100%|██████████| 579/579 [00:00<00:00, 1.63MB/s]\n",
      "spm.model: 100%|██████████| 2.46M/2.46M [00:02<00:00, 1.18MB/s]\n",
      "/Users/srishtysuman/anaconda3/envs/langchain/lib/python3.11/site-packages/transformers/convert_slow_tokenizer.py:473: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"microsoft/deberta-v3-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "class MyDataset(Dataset):\n",
    "    def __init__(self, dataset):\n",
    "        self.dataset = dataset\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "      chosen = self.dataset.chosen[idx].text()\n",
    "      rejected = self.dataset.rejected[idx].text()\n",
    "\n",
    "      tokenized_chosen = tokenizer(chosen, truncation=True, max_length=max_length, padding='max_length')\n",
    "      tokenized_rejected = tokenizer(rejected, truncation=True, max_length=max_length, padding='max_length')\n",
    "\n",
    "      formatted_input = {\n",
    "        \"input_ids_chosen\": tokenized_chosen[\"input_ids\"],\n",
    "        \"attention_mask_chosen\": tokenized_chosen[\"attention_mask\"],\n",
    "        \"input_ids_rejected\": tokenized_rejected[\"input_ids\"],\n",
    "        \"attention_mask_rejected\": tokenized_rejected[\"attention_mask\"],\n",
    "      }\n",
    "\n",
    "      return formatted_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = MyDataset(ds)\n",
    "eval_dataset = MyDataset(ds_valid)\n",
    "\n",
    "# Print one sample row\n",
    "iterator = iter(train_dataset)\n",
    "one_sample = next(iterator)\n",
    "print(list(one_sample.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "pytorch_model.bin: 100%|██████████| 371M/371M [04:20<00:00, 1.43MB/s] \n",
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-v3-base and are newly initialized: ['classifier.weight', 'classifier.bias', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    \"microsoft/deberta-v3-base\", num_labels=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"DeBERTa-reward-hh_rlhf\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=24,\n",
    "    per_device_eval_batch_size=24,\n",
    "    num_train_epochs=20,\n",
    "    weight_decay=0.001,\n",
    "    evaluation_strategy=\"steps\",\n",
    "    eval_steps=500,\n",
    "    save_strategy=\"steps\",\n",
    "    save_steps=500,\n",
    "    gradient_accumulation_steps=1,\n",
    "    bf16=True,\n",
    "    logging_strategy=\"steps\",\n",
    "    logging_steps=1,\n",
    "    optim=\"adamw_hf\",\n",
    "    lr_scheduler_type=\"linear\",\n",
    "    ddp_find_unused_parameters=False,\n",
    "    run_name=\"DeBERTa-reward-hh_rlhf\",\n",
    "    report_to=\"wandb\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from trl import RewardTrainer\n",
    "\n",
    "trainer = RewardTrainer(\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=eval_dataset,\n",
    "    max_length=max_length\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Reinforcement Learning (RL) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import deeplake\n",
    "from transformers import AutoTokenizer\n",
    "from torch.utils.data import Dataset\n",
    "from trl import PPOConfig\n",
    "from trl import set_seed\n",
    "from accelerate import Accelerator\n",
    "from peft import LoraConfig\n",
    "from trl import AutoModelForCausalLMWithValueHead\n",
    "from transformers import pipeline\n",
    "import torch\n",
    "from trl.core import LengthSampler\n",
    "from trl import PPOTrainer\n",
    "from tqdm import tqdm\n",
    "from transformers import AutoModelForCausalLM\n",
    "import torch\n",
    "from transformers import AutoModelForCausalLM, BitsAndBytesConfig\n",
    "import torch\n",
    "from transformers import AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\\"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opening dataset in read-only mode as you don't have write permissions.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "-"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This dataset can be visualized in Jupyter Notebook by ds.visualize() or at https://app.activeloop.ai/genai360/Alpaca-OrcaChat\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "|"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hub://genai360/Alpaca-OrcaChat loaded successfully.\n",
      "\n",
      "Dataset(path='hub://genai360/Alpaca-OrcaChat', read_only=True, tensors=['input', 'instruction', 'output'])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " "
     ]
    }
   ],
   "source": [
    "# Connect to the training and testing datasets\n",
    "ds = deeplake.load('hub://genai360/Alpaca-OrcaChat')\n",
    "print(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"facebook/opt-1.3b\", padding_side='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset(Dataset):\n",
    "    def __init__(self, ds):\n",
    "        self.ds = ds\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.ds)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "      query = \"Question: \" + self.ds.input[idx].text() + \"\\n\\nAnswer: \"\n",
    "      tokenized_question = tokenizer(query, truncation=True, max_length=400, padding='max_length', return_tensors=\"pt\")\n",
    "\n",
    "      formatted_input = {\n",
    "        \"query\": query,\n",
    "        \"input_ids\": tokenized_question[\"input_ids\"][0],\n",
    "      }\n",
    "\n",
    "      return formatted_input\n",
    "\n",
    "# Define the dataset object\n",
    "myTrainingLoader = MyDataset(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collator(data):\n",
    "    return dict((key, [d[key] for d in data]) for key in data[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Initialize the SFT Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = PPOConfig(\n",
    "    task_name=\"OPT-RL-OrcaChat\",\n",
    "    steps=10_000,\n",
    "    model_name=\"./OPT-fine_tuned-OpenOrca/merged\",\n",
    "    learning_rate=1.41e-5,\n",
    "    batch_size=32,\n",
    "    mini_batch_size=4,\n",
    "    gradient_accumulation_steps=1,\n",
    "    optimize_cuda_cache=True,\n",
    "    early_stopping=False,\n",
    "    target_kl=0.1,\n",
    "    ppo_epochs=4,\n",
    "    seed=0,\n",
    "    init_kl_coef=0.2,\n",
    "    adap_kl_ctrl=True,\n",
    "    tracker_project_name=\"GenAI360\",\n",
    "    log_with=\"wandb\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set seed before initializing value head for deterministic eval\n",
    "set_seed(config.seed)\n",
    "\n",
    "# Now let's build the model, the reference model, and the tokenizer.\n",
    "current_device = Accelerator().local_process_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lora_config = LoraConfig(\n",
    "    r=16,\n",
    "    lora_alpha=32,\n",
    "    lora_dropout=0.05,\n",
    "    bias=\"none\",\n",
    "    task_type=\"CAUSAL_LM\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelForCausalLMWithValueHead.from_pretrained(\n",
    "    config.model_name,\n",
    "    load_in_8bit=True,\n",
    "    device_map={\"\": current_device},\n",
    "    peft_config=lora_config,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reward_pipeline = pipeline(\n",
    "    \"sentiment-analysis\",\n",
    "    model=\"./DeBERTa-v3-base-reward-hh_rlhf/checkpoint-1000\",\n",
    "    tokenizer=\"./DeBERTa-v3-base-reward-hh_rlhf/checkpoint-1000\",\n",
    "    device_map={\"\": current_device},\n",
    "    model_kwargs={\"load_in_8bit\": True},\n",
    "    return_token_type_ids=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_length_sampler = LengthSampler(32, 400) #(OutputMinLength, OutputMaxLength)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sft_gen_kwargs = {\n",
    "    \"top_k\": 0.0,\n",
    "    \"top_p\": 1.0,\n",
    "    \"do_sample\": True,\n",
    "    \"pad_token_id\": tokenizer.pad_token_id,\n",
    "    \"eos_token_id\": 100_000,\n",
    "}\n",
    "\n",
    "reward_gen_kwargs = {\n",
    "    \"top_k\": None,\n",
    "    \"function_to_apply\": \"none\",\n",
    "    \"batch_size\": 16,\n",
    "    \"truncation\": True,\n",
    "    \"max_length\": 400\n",
    "}\n",
    "\n",
    "save_freq = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ppo_trainer = PPOTrainer(\n",
    "    config,\n",
    "    model,\n",
    "    tokenizer=tokenizer,\n",
    "    dataset=myTrainingLoader,\n",
    "    data_collator=collator\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tqdm.pandas()\n",
    "\n",
    "for step, batch in tqdm(enumerate(ppo_trainer.dataloader)):\n",
    "    if step >= config.total_ppo_epochs:\n",
    "        break\n",
    "    question_tensors = batch[\"input_ids\"]\n",
    "\n",
    "    response_tensors = ppo_trainer.generate(\n",
    "        question_tensors,\n",
    "        return_prompt=False,\n",
    "        length_sampler=output_length_sampler,\n",
    "        **sft_gen_kwargs,\n",
    "    )\n",
    "    batch[\"response\"] = tokenizer.batch_decode(response_tensors, skip_special_tokens=True)\n",
    "\n",
    "    # Compute reward score\n",
    "    texts = [q + r for q, r in zip(batch[\"query\"], batch[\"response\"])]\n",
    "    pipe_outputs = reward_pipeline(texts, **reward_gen_kwargs)\n",
    "\n",
    "    rewards = [torch.tensor(output[0][\"score\"]) for output in pipe_outputs]\n",
    "\n",
    "    # Run PPO step\n",
    "    stats = ppo_trainer.step(question_tensors, response_tensors, rewards)\n",
    "    ppo_trainer.log_stats(stats, batch, rewards)\n",
    "\n",
    "    if save_freq and step and step % save_freq == 0:\n",
    "        print(\"Saving checkpoint.\")\n",
    "        ppo_trainer.save_pretrained(f\"./OPT-RL-OrcaChat/checkpoint-{step}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "  \"facebook/opt-1.3b\", return_dict=True, torch_dtype=torch.bfloat16\n",
    ")\n",
    "\n",
    "from peft import PeftModel\n",
    "\n",
    "# Load the Lora model\n",
    "model = PeftModel.from_pretrained(model, \"./OPT-RL-OrcaChat/checkpoint-400/\")\n",
    "model.eval()\n",
    "\n",
    "model = model.merge_and_unload()\n",
    "\n",
    "model.save_pretrained(\"./OPT-RL-OrcaChat/merged\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    QLoRA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "\tmodel_name_or_path='/name/or/path/to/your/model',\n",
    "\tload_in_4bit=True,\n",
    "\tdevice_map='auto',\n",
    "\ttorch_dtype=torch.bfloat16,\n",
    "\tquantization_config=BitsAndBytesConfig(\n",
    "\t\tload_in_4bit=True,\n",
    "\t\tbnb_4bit_compute_dtype=torch.bfloat16,\n",
    "\t\tbnb_4bit_use_double_quant=True,\n",
    "\t\tbnb_4bit_quant_type='nf4'\n",
    "\t),\n",
    "\t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"facebook/opt-1.3b\")\n",
    "\n",
    "from transformers import AutoModelForCausalLM\n",
    "from accelerate import Accelerator\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    \"./OPT-RL-OrcaChat/merged\", device_map={\"\": Accelerator().process_index}\n",
    ")\n",
    "model.eval()\n",
    "\n",
    "inputs = tokenizer(\"Question: In one sentence, describe what the following article is about:\\n\\nClick on “Store” along the menu toolbar at the upper left of the screen. Click on “Sign In” from the drop-down menu and enter your Apple ID and password. After logging in, click on “Store” on the toolbar again and select “View Account” from the drop-down menu. This will open the Account Information page.  Click on the drop-down list and select the country you want to change your iTunes Store to.  You’ll now be directed to the iTunes Store welcome page. Review the Terms and Conditions Agreement and click on “Agree” if you wish to proceed. Click on “Continue” once you’re done to complete changing your iTunes Store..\\n\\n Answer: \", return_tensors=\"pt\").to(\"cuda:0\")\n",
    "generation_output = model.generate(**inputs,\n",
    "                                   return_dict_in_generate=True,\n",
    "                                   output_scores=True,\n",
    "                                   max_new_tokens=128,\n",
    "                                   num_beams=4,\n",
    "                                   do_sample=True,\n",
    "                                   top_k=10,\n",
    "                                   temperature=0.6)\n",
    "print( tokenizer.decode(generation_output['sequences'][0]) )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
