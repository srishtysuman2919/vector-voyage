{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import SeleniumURLLoader\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.vectorstores import DeepLake\n",
    "from langchain import PromptTemplate\n",
    "from langchain.llms import OpenAI\n",
    "from langchain import LLMChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we'll use information from the following articles\n",
    "urls = ['https://beebom.com/what-is-nft-explained/',\n",
    "        'https://beebom.com/how-delete-spotify-account/',\n",
    "        'https://beebom.com/how-install-pip-windows/',\n",
    "        'https://beebom.com/how-check-disk-usage-linux/']\n",
    "\n",
    "# 1: Load the data from urls\n",
    "loader = SeleniumURLLoader(urls=urls)\n",
    "entire_data = loader.load()\n",
    "\n",
    "# 2: Split them into chunks using the CharacterTextSplitter with a chunk size of 1000 and no overlap:\n",
    "text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
    "data = text_splitter.split_documents(entire_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/srishtysuman/anaconda3/envs/langchain/lib/python3.11/site-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The class `langchain_community.embeddings.openai.OpenAIEmbeddings` was deprecated in langchain-community 0.1.0 and will be removed in 0.2.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import OpenAIEmbeddings`.\n",
      "  warn_deprecated(\n"
     ]
    }
   ],
   "source": [
    "# 3: Compute the embeddings using OpenAIEmbeddings\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-ada-002\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using embedding function is deprecated and will be removed in the future. Please use embedding instead.\n",
      "Creating 65 embeddings in 1 batches of size 65:: 100%|██████████| 1/1 [00:05<00:00,  5.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset(path='https:/app.activeloop.ai/srishtysuman2919/customer_support_chatbot', tensors=['text', 'metadata', 'embedding', 'id'])\n",
      "\n",
      "  tensor      htype      shape      dtype  compression\n",
      "  -------    -------    -------    -------  ------- \n",
      "   text       text      (65, 1)      str     None   \n",
      " metadata     json      (65, 1)      str     None   \n",
      " embedding  embedding  (65, 1536)  float32   None   \n",
      "    id        text      (65, 1)      str     None   \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['1454c308-c6b0-11ee-ba01-acde48001122',\n",
       " '1454c3f8-c6b0-11ee-ba01-acde48001122',\n",
       " '1454c48e-c6b0-11ee-ba01-acde48001122',\n",
       " '1454c51a-c6b0-11ee-ba01-acde48001122',\n",
       " '1454c556-c6b0-11ee-ba01-acde48001122',\n",
       " '1454c592-c6b0-11ee-ba01-acde48001122',\n",
       " '1454c5ba-c6b0-11ee-ba01-acde48001122',\n",
       " '1454c628-c6b0-11ee-ba01-acde48001122',\n",
       " '1454c664-c6b0-11ee-ba01-acde48001122',\n",
       " '1454c68c-c6b0-11ee-ba01-acde48001122',\n",
       " '1454c6be-c6b0-11ee-ba01-acde48001122',\n",
       " '1454c6e6-c6b0-11ee-ba01-acde48001122',\n",
       " '1454c70e-c6b0-11ee-ba01-acde48001122',\n",
       " '1454c736-c6b0-11ee-ba01-acde48001122',\n",
       " '1454c75e-c6b0-11ee-ba01-acde48001122',\n",
       " '1454c786-c6b0-11ee-ba01-acde48001122',\n",
       " '1454c7ae-c6b0-11ee-ba01-acde48001122',\n",
       " '1454c7d6-c6b0-11ee-ba01-acde48001122',\n",
       " '1454c7fe-c6b0-11ee-ba01-acde48001122',\n",
       " '1454c826-c6b0-11ee-ba01-acde48001122',\n",
       " '1454c844-c6b0-11ee-ba01-acde48001122',\n",
       " '1454c86c-c6b0-11ee-ba01-acde48001122',\n",
       " '1454c894-c6b0-11ee-ba01-acde48001122',\n",
       " '1454c8bc-c6b0-11ee-ba01-acde48001122',\n",
       " '1454c8e4-c6b0-11ee-ba01-acde48001122',\n",
       " '1454c90c-c6b0-11ee-ba01-acde48001122',\n",
       " '1454c934-c6b0-11ee-ba01-acde48001122',\n",
       " '1454c95c-c6b0-11ee-ba01-acde48001122',\n",
       " '1454c984-c6b0-11ee-ba01-acde48001122',\n",
       " '1454c9ac-c6b0-11ee-ba01-acde48001122',\n",
       " '1454c9d4-c6b0-11ee-ba01-acde48001122',\n",
       " '1454c9fc-c6b0-11ee-ba01-acde48001122',\n",
       " '1454ca1a-c6b0-11ee-ba01-acde48001122',\n",
       " '1454ca42-c6b0-11ee-ba01-acde48001122',\n",
       " '1454ca6a-c6b0-11ee-ba01-acde48001122',\n",
       " '1454ca92-c6b0-11ee-ba01-acde48001122',\n",
       " '1454caba-c6b0-11ee-ba01-acde48001122',\n",
       " '1454cae2-c6b0-11ee-ba01-acde48001122',\n",
       " '1454cb00-c6b0-11ee-ba01-acde48001122',\n",
       " '1454cb28-c6b0-11ee-ba01-acde48001122',\n",
       " '1454cb50-c6b0-11ee-ba01-acde48001122',\n",
       " '1454cb78-c6b0-11ee-ba01-acde48001122',\n",
       " '1454cba0-c6b0-11ee-ba01-acde48001122',\n",
       " '1454cbc8-c6b0-11ee-ba01-acde48001122',\n",
       " '1454cbf0-c6b0-11ee-ba01-acde48001122',\n",
       " '1454cc36-c6b0-11ee-ba01-acde48001122',\n",
       " '1454cc68-c6b0-11ee-ba01-acde48001122',\n",
       " '1454cc90-c6b0-11ee-ba01-acde48001122',\n",
       " '1454ccb8-c6b0-11ee-ba01-acde48001122',\n",
       " '1454ccd6-c6b0-11ee-ba01-acde48001122',\n",
       " '1454ccfe-c6b0-11ee-ba01-acde48001122',\n",
       " '1454cd26-c6b0-11ee-ba01-acde48001122',\n",
       " '1454cd4e-c6b0-11ee-ba01-acde48001122',\n",
       " '1454cd76-c6b0-11ee-ba01-acde48001122',\n",
       " '1454cd9e-c6b0-11ee-ba01-acde48001122',\n",
       " '1454cdc6-c6b0-11ee-ba01-acde48001122',\n",
       " '1454cdee-c6b0-11ee-ba01-acde48001122',\n",
       " '1454ce16-c6b0-11ee-ba01-acde48001122',\n",
       " '1454ce3e-c6b0-11ee-ba01-acde48001122',\n",
       " '1454ce66-c6b0-11ee-ba01-acde48001122',\n",
       " '1454ce8e-c6b0-11ee-ba01-acde48001122',\n",
       " '1454ceb6-c6b0-11ee-ba01-acde48001122',\n",
       " '1454cede-c6b0-11ee-ba01-acde48001122',\n",
       " '1454cefc-c6b0-11ee-ba01-acde48001122',\n",
       " '1454cf24-c6b0-11ee-ba01-acde48001122']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 4: store them in a Deep Lake vector store on the cloud\n",
    "my_activeloop_org_id = \"srishtysuman2919\" \n",
    "customer_support_chatbot = \"customer_support_chatbot\"\n",
    "dataset_path = f\"https:/app.activeloop.ai/srishtysuman2919/{customer_support_chatbot}\"\n",
    "db = DeepLake(dataset_path=dataset_path, embedding_function=embeddings)\n",
    "db.add_documents(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Check Disk Usage Using Gnome Disk Tool\n",
      "\n",
      "Check Disk Usage Using Disk Usage Analyzer Tool\n",
      "\n",
      "Cleanup Disk using Disk Usage Analyzer\n",
      "\n",
      "Check Disk Space Using the df Command\n",
      "\n",
      "In Linux, there are many commands to check disk usage, the most common being the df command. The df stands for “Disk Filesystem” in the command, which is a handy way to check the current disk usage and the available disk space in Linux. The syntax for the df command in Linux is as follows:\n",
      "\n",
      "df <options> <file_system>\n",
      "\n",
      "The options to use with the df command are:\n",
      "\n",
      "a\n",
      "\n",
      "Show information about all file systems including pseudo, duplicate and inaccessible file systems\n",
      "\n",
      "h\n",
      "\n",
      "Display the sizes in human-readable format i.e in powers of 1024\n",
      "\n",
      "t\n",
      "\n",
      "Display the disk usage of only the file system of a particular type\n",
      "\n",
      "x\n",
      "\n",
      "Display the disk usage excluding a particular file type\n",
      "\n",
      "Display Disk Usage in Human Readable Format\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/srishtysuman/anaconda3/envs/langchain/lib/python3.11/site-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The class `langchain_community.llms.openai.OpenAI` was deprecated in langchain-community 0.0.10 and will be removed in 0.2.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import OpenAI`.\n",
      "  warn_deprecated(\n",
      "/Users/srishtysuman/anaconda3/envs/langchain/lib/python3.11/site-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The function `__call__` was deprecated in LangChain 0.1.7 and will be removed in 0.2.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " There are several ways to check disk usage in Linux. One of the most common methods is by using the df command. You can use the options \"a\" to show information about all file systems, \"h\" to display sizes in human-readable format, \"t\" to display disk usage of a particular file system type, or \"x\" to exclude a specific file type. Another way is by using GUI tools such as the Gnome Disk Tool or the Disk Usage Analyzer Tool. These tools provide a visual representation of disk usage and allow you to easily identify and delete large files or folders.\n"
     ]
    }
   ],
   "source": [
    "# 5: To retrieve the most similar chunks to a given query, we can use the similarity_search method of the Deep Lake vector store\n",
    "query = \"how to check disk usage in linux?\"\n",
    "docs = db.similarity_search(query)\n",
    "print(docs[0].page_content)\n",
    "\n",
    "# 6: Craft a prompt for GPT-3-> create a prompt template that incorporates role-prompting, relevant Knowledge Base information, and the user's question:\n",
    "# let's write a prompt for a customer support chatbot that\n",
    "# answer questions using information extracted from our db\n",
    "template = \"\"\"You are an exceptional customer support chatbot that gently answer questions.\n",
    "\n",
    "You know the following context information.\n",
    "\n",
    "{chunks_formatted}\n",
    "\n",
    "Answer to the following question from a customer. Use only information from the previous context information. Do not invent stuff.\n",
    "\n",
    "Question: {query}\n",
    "\n",
    "Answer:\"\"\"\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"chunks_formatted\", \"query\"],\n",
    "    template=template,\n",
    ")\n",
    "\n",
    "# 7: Utilize the GPT3 model with a temperature of 0 for text generation\n",
    "llm = OpenAI(model=\"gpt-3.5-turbo-instruct\", temperature=0)\n",
    "\n",
    "# user question\n",
    "query = \"How to check disk usage in linux?\"\n",
    "\n",
    "# 8: retrieve relevant chunks\n",
    "docs = db.similarity_search(query)\n",
    "retrieved_chunks = [doc.page_content for doc in docs]\n",
    "\n",
    "# 9: format the prompt\n",
    "chunks_formatted = \"\\n\\n\".join(retrieved_chunks)\n",
    "prompt_formatted = prompt.format(chunks_formatted=chunks_formatted, query=query)\n",
    "\n",
    "# 10: generate answer\n",
    "answer = llm(prompt_formatted)\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
