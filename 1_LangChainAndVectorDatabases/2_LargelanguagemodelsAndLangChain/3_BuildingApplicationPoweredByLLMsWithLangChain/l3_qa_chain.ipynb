{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    We can also use LangChain to manage prompts for asking general questions from the LLMs. \n",
    "    These models are proficient in addressing fundamental inquiries. \n",
    "    Nevertheless, it is crucial to remain mindful of the potential issue of hallucinations, where the models may generate non-factual information. \n",
    "    To address this concern, we will later introduce the Retrieval chain as a means to overcome this problem.\n",
    "'''\n",
    "\n",
    "from langchain.llms import OpenAI\n",
    "from langchain import PromptTemplate, LLMChain\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv('/Users/srishtysuman/.env')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = OpenAI(model_name=\"gpt-3.5-turbo-instruct\", temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = PromptTemplate(template=\"Question: {question}\\nAnswer:\", input_variables=[\"question\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' The meaning of life is a philosophical question that has been debated by many thinkers and scholars throughout history. Some believe that the meaning of life is to find happiness and fulfillment, while others believe it is to fulfill a certain purpose or destiny. Ultimately, the meaning of life may vary for each individual and can be influenced by personal beliefs, values, and experiences.'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain = LLMChain(llm=llm, prompt=prompt)\n",
    "\n",
    "# We define a custom prompt template by creating an instance of the PromptTemplate class. \n",
    "# The template string contains a placeholder {question} for the input question, followed by a newline character and the \"Answer:\" label.  \n",
    "# The input_variables argument is set to the list of available placeholders in the prompt (like a question in this case) \n",
    "# to indicate the name of the variable that the chain will replace in the template.run() method.\n",
    "\n",
    "# We then instantiate an OpenAI model named text-davinci-003 with a temperature of 0. \n",
    "# The OpenAI class is used to create the instance, and the model_name and temperature arguments are provided. \n",
    "# Finally, we create a question-answering chain using the LLMChain class. \n",
    "\n",
    "# The class constructor takes two arguments: llm, which is the instantiated OpenAI model, and prompt, which is the custom prompt template we defined earlier. \n",
    "\n",
    "# By following these steps, we can process input questions effectively with the custom question-answering, \n",
    "# generating appropriate answers using the OpenAI model and the custom prompt template.\n",
    "\n",
    "chain.run(\"what is the meaning of life?\")\n",
    "\n",
    "# This example demonstrates how LangChain simplifies the integration of LLMs with custom data sources and prompt templates for question-answering applications. \n",
    "# To build more advanced NLP applications, you can further extend this example to include other components, such as data-augmented generation, agents, or memory features.\n",
    "\n",
    "# LangChain's support for chain sequences also allows developers to create more complex applications with multiple calls to LLMs or other utilities. \n",
    "# These chains can serve various purposes: personal assistants, chatbots, querying tabular data, interacting with APIs, extraction, evaluation, and summarization.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
