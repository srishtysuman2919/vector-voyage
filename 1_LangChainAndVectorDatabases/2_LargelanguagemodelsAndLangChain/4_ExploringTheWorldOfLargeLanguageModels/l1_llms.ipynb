{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    Large Language Models have made significant advancements in the field of Natural Language Processing (NLP), enabling AI systems to understand and generate human-like text. \n",
    "    ChatGPT is a popular language model based on Transformers architecture, enabling it to understand long texts and figure out how words or ideas are connected. \n",
    "    It's great at making predictions about language and relationships between words.\n",
    "\n",
    "    LLMs and Chat Models are two types of models in LangChain, serving different purposes in natural language processing tasks.\n",
    "\n",
    "    LLMs, such as GPT-3, Bloom, PaLM, and Aurora genAI, take a text string as input and return a text string as output. \n",
    "    They are trained on language modeling tasks and can generate human-like text, perform complex reasoning, and even write code. \n",
    "    LLMs are powerful and flexible, capable of generating text for a wide range of tasks. \n",
    "    However, they can sometimes produce incorrect or nonsensical answers, and their API is less structured compared to Chat Models.\n",
    "\n",
    "    Pre-training these models involves presenting large-scale corpora to them and allowing the network to predict the next word, \n",
    "    which results in learning the relationships between words. This learning process enables LLMs to generate high-quality text, \n",
    "    which can be applied to an array of applications, such as automatic form-filling and predictive text on smartphones.\n",
    "\n",
    "    Most of these models are trained on general purpose training dataset, while others are trained on a mix of general and domain-specific data, \n",
    "    such as Intel Aurora genAI, which is trained on general text, scientific texts, scientific data, and codes related to the domain. \n",
    "    The goal of domain specific LLMs is to increase the performance on a particularly domain, while still being able to solve the majority of tasks that general LLM can manage.\n",
    "\n",
    "    LLMs have the potential to infiltrate various aspects of human life, including the arts, sciences, and law. \n",
    "    With continued development, LLMs will become increasingly integrated into our educational, personal, and professional lives, making them an essential technology to master.\n",
    "'''\n",
    "\n",
    "# Import the OpenAI wrapper from the langchain.llms module and Initialize it with the desired model name and any additional arguments. \n",
    "# For example, set a high temperature for more random outputs. Then, create a PromptTemplate to format the input for the model. \n",
    "# Lastly, define an LLMChain to combine the model and prompt. Run the chain with the desired input using .run()\n",
    "\n",
    "from langchain.llms import OpenAI\n",
    "from langchain import PromptTemplate, LLMChain\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv('/Users/srishtysuman/.env')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm=OpenAI(model=\"gpt-3.5-turbo-instruct\", temperature=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt=PromptTemplate(input_variables=[\"product\"], template=\"What is a good name for a company that makes {product}?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain=LLMChain(llm=llm, prompt=prompt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\n1. SoundWave\\n2. AirBeats\\n3. Wireless Audio Co.\\n4. EarFreedom\\n5. SonicWire\\n6. HeadSync\\n7. BlueTunes\\n8. PureWireless\\n9. AudioLink\\n10. FreeFlow Headphones'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.run(\"wireless headphones\")\n",
    "\n",
    "# Here, the input for the chain is the string \"wireless headphones\". The chain processes the input and generates a result based on the product name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
