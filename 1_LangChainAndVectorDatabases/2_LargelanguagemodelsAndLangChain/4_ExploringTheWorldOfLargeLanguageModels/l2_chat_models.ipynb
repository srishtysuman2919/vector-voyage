{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    Chat Models are the most popular models in LangChain, such as ChatGPT that can incorporate GPT-3 or GPT-4 at its core. \n",
    "    They have gained significant attention due to their ability to learn from human feedback and their user-friendly chat interface.\n",
    "\n",
    "    Chat Models, such as ChatGPT, take a list of messages as input and return an AIMessage. \n",
    "    They typically use LLMs as their underlying technology, but their APIs are more structured. \n",
    "    Chat Models are designed to remember previous exchanges with the user in a session and use that context to generate more relevant responses. \n",
    "    They also benefit from reinforcement learning from human feedback, which helps improve their responses. \n",
    "    However, they may still have limitations in reasoning and require careful handling to avoid generating inappropriate content.\n",
    "\n",
    "    In LangChain, three main types of messages are used when interacting with chat models: SystemMessage, HumanMessage, and AIMessage.\n",
    "        SystemMessage: These messages provide initial instructions, context, or data for the AI model. \n",
    "                       They set the objectives the AI should follow and can help in controlling the AI's behavior.\n",
    "                       System messages are not user inputs but rather guidelines for the AI to operate within.\n",
    "\n",
    "                       SystemMessage represents the messages generated by the system that wants to use the model, \n",
    "                       which could include instructions, notifications, or error messages. \n",
    "                       These messages are not generated by the human user or the AI chatbot but are instead produced by the underlying system \n",
    "                       to provide context, guidance, or status updates.\n",
    "\n",
    "        HumanMessage: These messages come from the user and represent their input to the AI model. \n",
    "                      The AI model is expected to respond to these messages. \n",
    "                      In LangChain, you can customize the human prefix (e.g., \"User\") in the conversation summary to change how the human input is represented.\n",
    "\n",
    "        AIMessage: These messages are sent from the AI's perspective as it interacts with the human user. \n",
    "                   They represent the AI's responses to human input. \n",
    "                   Like HumanMessage, we can also customize the AI prefix (e.g., \"AI Assistant\" or \"AI\") in the conversation summary to change how the AI's responses are represented.\n",
    "''' \n",
    "\n",
    "# In this section, we are trying to use the LangChain library to create a chatbot that can translate an English sentence into French. \n",
    "# This particular use case goes beyond what we covered in the previous lesson. \n",
    "# We'll be employing multiple message types to differentiate between users' queries and system instructions instead of relying on a single prompt. \n",
    "# This approach will enhance the model's comprehension of the given requirements.\n",
    "\n",
    "# First, we create a list of messages, starting with a SystemMessage that sets the context for the chatbot, \n",
    "# informing it that its role is to be a helpful assistant translating English to French. \n",
    "# We then follow it with a HumanMessage containing the userâ€™s query, like an English sentence to be translated.\n",
    "\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.schema import (SystemMessage, HumanMessage)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"J'adore la programmation.\")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages = [\n",
    "\tSystemMessage(content=\"You are a helpful assistant that translates English to French.\"),\n",
    "\tHumanMessage(content=\"Translate the following sentence: I love programming.\")\n",
    "]\n",
    "\n",
    "chat(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generations=[[ChatGeneration(text=\"J'adore la programmation.\", generation_info={'finish_reason': 'stop'}, message=AIMessage(content=\"J'adore la programmation.\"))], [ChatGeneration(text='I like programming.', generation_info={'finish_reason': 'stop'}, message=AIMessage(content='I like programming.'))]] llm_output={'token_usage': {'completion_tokens': 12, 'prompt_tokens': 65, 'total_tokens': 77}, 'model_name': 'gpt-3.5-turbo'} run=[RunInfo(run_id=UUID('5743aa5e-a0d7-4634-bfd0-7f39f7f94bb3')), RunInfo(run_id=UUID('4ee1720e-9c68-4cc4-8839-42680f84fa8c'))]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "# we pass the list of messages to the chatbot using the chat() function. \n",
    "# The chatbot processes the input messages, considers the context provided by the system message, and then translates the given English sentence into French. \n",
    "\n",
    "# Using the generate method, you can also generate completions for multiple sets of messages. \n",
    "# Each batch of messages can have its own SystemMessage and will perform independently. \n",
    "# The following code shows the first set of messages translate the sentences from English to French, while the second ones do the opposite.\n",
    "\n",
    "batch_messages = [\n",
    "  [\n",
    "    SystemMessage(content=\"You are a helpful assistant that translates English to French.\"),\n",
    "    HumanMessage(content=\"Translate the following sentence: I love programming.\")\n",
    "  ],\n",
    "  [\n",
    "    SystemMessage(content=\"You are a helpful assistant that translates French to English.\"),\n",
    "    HumanMessage(content=\"Translate the following sentence: J'aime la programmation.\")\n",
    "  ],\n",
    "]\n",
    "print( chat.generate(batch_messages) )\n",
    "\n",
    "# LLMs and Chat Models each have their advantages and disadvantages. LLMs are powerful and flexible, capable of generating text for a wide range of tasks. \n",
    "# However, their API is less structured compared to Chat Models.\n",
    "\n",
    "# On the other hand, Chat Models offer a more structured API and are better suited for conversational tasks. \n",
    "# Also, they can remember previous exchanges with the user, making them more suitable for engaging in meaningful conversations. \n",
    "# Additionally, they benefit from reinforcement learning from human feedback, which helps improve their responses. \n",
    "# They still have some limitations in reasoning and may require careful handling to avoid hallucinations and generating inappropriate content.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
