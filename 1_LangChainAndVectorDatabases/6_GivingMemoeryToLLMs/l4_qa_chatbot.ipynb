{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RetrievalQAWithSourcesChain: retrieves answers and tracks their sources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from newspaper import Article\n",
    "import time\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.vectorstores import DeepLake\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.chains import RetrievalQAWithSourcesChain\n",
    "from langchain import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = {\n",
    "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/89.0.4389.82 Safari/537.36'\n",
    "}\n",
    "\n",
    "article_urls = [\n",
    "    \"https://www.artificialintelligence-news.com/2023/05/16/openai-ceo-ai-regulation-is-essential/\",\n",
    "    \"https://www.artificialintelligence-news.com/2023/05/15/jay-migliaccio-ibm-watson-on-leveraging-ai-to-improve-productivity/\",\n",
    "    \"https://www.artificialintelligence-news.com/2023/05/15/iurii-milovanov-softserve-how-ai-ml-is-helping-boost-innovation-and-personalisation/\",\n",
    "    \"https://www.artificialintelligence-news.com/2023/05/11/ai-and-big-data-expo-north-america-begins-in-less-than-one-week/\",\n",
    "    \"https://www.artificialintelligence-news.com/2023/05/02/ai-godfather-warns-dangers-and-quits-google/\",\n",
    "    \"https://www.artificialintelligence-news.com/2023/04/28/palantir-demos-how-ai-can-used-military/\"\n",
    "]\n",
    "\n",
    "session = requests.Session()\n",
    "pages_content = [] # where we save the scraped articles\n",
    "\n",
    "for url in article_urls:\n",
    "    try:\n",
    "        time.sleep(2) # sleep two seconds for gentle scraping\n",
    "        response = session.get(url, headers=headers, timeout=10)\n",
    "\n",
    "        if response.status_code == 200:\n",
    "            article = Article(url)\n",
    "            article.download() # download HTML of webpage\n",
    "            article.parse() # parse HTML to extract the article text\n",
    "            pages_content.append({ \"url\": url, \"text\": article.text })\n",
    "        else:\n",
    "            print(f\"Failed to fetch article at {url}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error occurred while fetching article at {url}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/srishtysuman/anaconda3/envs/langchain/lib/python3.11/site-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The class `langchain_community.embeddings.openai.OpenAIEmbeddings` was deprecated in langchain-community 0.1.0 and will be removed in 0.2.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import OpenAIEmbeddings`.\n",
      "  warn_deprecated(\n"
     ]
    }
   ],
   "source": [
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-ada-002\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using embedding function is deprecated and will be removed in the future. Please use embedding instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your Deep Lake dataset has been successfully created!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " \r"
     ]
    }
   ],
   "source": [
    "my_activeloop_org_id = \"srishtysuman2919\"\n",
    "my_activeloop_dataset_name = \"langchain_course_qabot_with_source\"\n",
    "dataset_path = f\"hub://{my_activeloop_org_id}/{my_activeloop_dataset_name}\"\n",
    "db = DeepLake(dataset_path=dataset_path, embedding_function=embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating 49 embeddings in 1 batches of size 49:: 100%|██████████| 1/1 [00:40<00:00, 40.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset(path='hub://srishtysuman2919/langchain_course_qabot_with_source', tensors=['text', 'metadata', 'embedding', 'id'])\n",
      "\n",
      "  tensor      htype      shape      dtype  compression\n",
      "  -------    -------    -------    -------  ------- \n",
      "   text       text      (49, 1)      str     None   \n",
      " metadata     json      (49, 1)      str     None   \n",
      " embedding  embedding  (49, 1536)  float32   None   \n",
      "    id        text      (49, 1)      str     None   \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['ab5e6052-c678-11ee-a35e-acde48001122',\n",
       " 'ab5e6200-c678-11ee-a35e-acde48001122',\n",
       " 'ab5e62d2-c678-11ee-a35e-acde48001122',\n",
       " 'ab5e6322-c678-11ee-a35e-acde48001122',\n",
       " 'ab5e6372-c678-11ee-a35e-acde48001122',\n",
       " 'ab5e63ae-c678-11ee-a35e-acde48001122',\n",
       " 'ab5e63f4-c678-11ee-a35e-acde48001122',\n",
       " 'ab5e6458-c678-11ee-a35e-acde48001122',\n",
       " 'ab5e64a8-c678-11ee-a35e-acde48001122',\n",
       " 'ab5e64e4-c678-11ee-a35e-acde48001122',\n",
       " 'ab5e6520-c678-11ee-a35e-acde48001122',\n",
       " 'ab5e655c-c678-11ee-a35e-acde48001122',\n",
       " 'ab5e65a2-c678-11ee-a35e-acde48001122',\n",
       " 'ab5e65de-c678-11ee-a35e-acde48001122',\n",
       " 'ab5e661a-c678-11ee-a35e-acde48001122',\n",
       " 'ab5e664c-c678-11ee-a35e-acde48001122',\n",
       " 'ab5e6728-c678-11ee-a35e-acde48001122',\n",
       " 'ab5e67be-c678-11ee-a35e-acde48001122',\n",
       " 'ab5e67fa-c678-11ee-a35e-acde48001122',\n",
       " 'ab5e6822-c678-11ee-a35e-acde48001122',\n",
       " 'ab5e6854-c678-11ee-a35e-acde48001122',\n",
       " 'ab5e6890-c678-11ee-a35e-acde48001122',\n",
       " 'ab5e68cc-c678-11ee-a35e-acde48001122',\n",
       " 'ab5e68f4-c678-11ee-a35e-acde48001122',\n",
       " 'ab5e694e-c678-11ee-a35e-acde48001122',\n",
       " 'ab5e6976-c678-11ee-a35e-acde48001122',\n",
       " 'ab5e6aa2-c678-11ee-a35e-acde48001122',\n",
       " 'ab5e6aca-c678-11ee-a35e-acde48001122',\n",
       " 'ab5e6af2-c678-11ee-a35e-acde48001122',\n",
       " 'ab5e6b10-c678-11ee-a35e-acde48001122',\n",
       " 'ab5e6b38-c678-11ee-a35e-acde48001122',\n",
       " 'ab5e6b56-c678-11ee-a35e-acde48001122',\n",
       " 'ab5e6b7e-c678-11ee-a35e-acde48001122',\n",
       " 'ab5e6ba6-c678-11ee-a35e-acde48001122',\n",
       " 'ab5e6bc4-c678-11ee-a35e-acde48001122',\n",
       " 'ab5e6bec-c678-11ee-a35e-acde48001122',\n",
       " 'ab5e6c0a-c678-11ee-a35e-acde48001122',\n",
       " 'ab5e6c32-c678-11ee-a35e-acde48001122',\n",
       " 'ab5e6c50-c678-11ee-a35e-acde48001122',\n",
       " 'ab5e6c6e-c678-11ee-a35e-acde48001122',\n",
       " 'ab5e6c96-c678-11ee-a35e-acde48001122',\n",
       " 'ab5e6cbe-c678-11ee-a35e-acde48001122',\n",
       " 'ab5e6cdc-c678-11ee-a35e-acde48001122',\n",
       " 'ab5e6d04-c678-11ee-a35e-acde48001122',\n",
       " 'ab5e6d22-c678-11ee-a35e-acde48001122',\n",
       " 'ab5e6d4a-c678-11ee-a35e-acde48001122',\n",
       " 'ab5e6d68-c678-11ee-a35e-acde48001122',\n",
       " 'ab5e6d90-c678-11ee-a35e-acde48001122',\n",
       " 'ab5e6dae-c678-11ee-a35e-acde48001122']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We split the article texts into small chunks. While doing so, we keep track of each\n",
    "# chunk metadata (i.e. the URL where it comes from). Each metadata is a dictionary and\n",
    "# we need to use the \"source\" key for the document source so that we can then use the\n",
    "# RetrievalQAWithSourcesChain class which will automatically retrieve the \"source\" item\n",
    "# from the metadata dictionary.\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=100)\n",
    "\n",
    "all_texts, all_metadatas = [], []\n",
    "for d in pages_content:\n",
    "    chunks = text_splitter.split_text(d[\"text\"])\n",
    "    for chunk in chunks:\n",
    "        all_texts.append(chunk)\n",
    "        all_metadatas.append({ \"source\": d[\"url\"] })\n",
    "\n",
    "# we add all the chunks to the deep lake, along with their metadata\n",
    "db.add_texts(all_texts, all_metadatas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/srishtysuman/anaconda3/envs/langchain/lib/python3.11/site-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The class `langchain_community.llms.openai.OpenAI` was deprecated in langchain-community 0.0.10 and will be removed in 0.2.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import OpenAI`.\n",
      "  warn_deprecated(\n",
      "/Users/srishtysuman/anaconda3/envs/langchain/lib/python3.11/site-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The function `__call__` was deprecated in LangChain 0.1.0 and will be removed in 0.2.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response:\n",
      " Geoffrey Hinton, known as the \"Godfather of AI,\" has expressed concerns about the potential dangers of AI and left his position at Google to discuss them openly. He has warned about the rapid development of generative AI products and the potential for false information to be spread. He also has concerns about the impact of AI on the job market. Other experts, such as Elon Musk, Neil deGrasse Tyson, and Stephen Hawking, have also expressed concerns about the risks of AI. \n",
      "\n",
      "Sources:\n",
      "- https://www.artificialintelligence-news.com/2023/05/02/ai-godfather-warns-dangers-and-quits-google/\n"
     ]
    }
   ],
   "source": [
    "# we create a RetrievalQAWithSourcesChain chain, which is very similar to a\n",
    "# standard retrieval QA chain but it also keeps track of the sources of the\n",
    "# retrieved documents\n",
    "llm = OpenAI(model_name=\"gpt-3.5-turbo-instruct\", temperature=0)\n",
    "\n",
    "\n",
    "# from_chain_type method: arguments-> 1. LLM: instance of a model (GPT-3 for eg;)\n",
    "#                                     2. chain_type: type of chain being used, which influences how the model processes the retrieved documents and generates responses. \n",
    "#                                     3. retriever: sets up the retriever that will fetch the relevant documents from the Deep Lake database. \n",
    "chain = RetrievalQAWithSourcesChain.from_chain_type(llm=llm,\n",
    "                                                    chain_type=\"stuff\",\n",
    "                                                    retriever=db.as_retriever())\n",
    "\n",
    "# We generate a response to a query using the chain. The response object is a dictionary containing\n",
    "# an \"answer\" field with the textual answer to the query, and a \"sources\" field containing a string made\n",
    "# of the concatenation of the metadata[\"source\"] strings of the retrieved documents.\n",
    "d_response = chain({\"question\": \"What does Geoffrey Hinton think about recent trends in AI?\"})\n",
    "\n",
    "print(\"Response:\")\n",
    "print(d_response[\"answer\"])\n",
    "print(\"Sources:\")\n",
    "for source in d_response[\"sources\"].split(\", \"):\n",
    "    print(\"- \" + source)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
